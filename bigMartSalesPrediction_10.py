{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c19acb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, VotingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as cbr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "122c36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_feature_engineering(df):\n",
    "    \"\"\"Apply advanced feature engineering techniques\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Fill missing values strategically\n",
    "    df['Item_Weight'].fillna(df.groupby('Item_Type')['Item_Weight'].transform('mean'), inplace=True)\n",
    "    df['Outlet_Size'].fillna(df.groupby('Outlet_Type')['Outlet_Size'].transform(\n",
    "        lambda x: x.mode()[0] if not x.mode().empty else \"Medium\"), inplace=True)\n",
    "    \n",
    "    \n",
    "    # Create interaction features\n",
    "    df['Price_per_Weight'] = df['Item_MRP'] / df['Item_Weight']\n",
    "    df['Outlet_Years'] = 2013 - df['Outlet_Establishment_Year']\n",
    "    \n",
    "    # Item Visibility improvements\n",
    "    df['Item_Visibility'] = df['Item_Visibility'].replace(0, df['Item_Visibility'].mean())\n",
    "    df['Item_Visibility_Normalized'] = df.groupby('Item_Type')['Item_Visibility'].transform(\n",
    "        lambda x: x / x.mean())\n",
    "    df['Item_Visibility_Ratio'] = df['Item_Visibility'] / df.groupby('Item_Type')['Item_Visibility'].transform('mean')\n",
    "    \n",
    "    \n",
    "    # MRP-related features\n",
    "    df['Item_MRP_Binned'] = pd.qcut(df['Item_MRP'], 10, labels=False)\n",
    "    df['Price_Level'] = pd.qcut(df['Item_MRP'], 4, labels=['Budget', 'Economy', 'Premium', 'Luxury'])\n",
    "    \n",
    "    \n",
    "    # Fat Content simplification\n",
    "    df['Item_Fat_Content'] = df['Item_Fat_Content'].replace({'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg': 'Regular'})\n",
    "    \n",
    "    # Item Type grouping\n",
    "    food_categories = ['Dairy', 'Soft Drinks', 'Meat', 'Fruits and Vegetables', 'Breakfast', \n",
    "                       'Seafood', 'Snack Foods', 'Baking Goods', 'Breads', 'Starchy Foods']\n",
    "    df['Item_Category'] = df['Item_Type'].apply(lambda x: 'Food' if x in food_categories else 'Non-Food')\n",
    "    \n",
    "    # Outlet Type and Size interaction\n",
    "    df['Outlet_Size_Type'] = df['Outlet_Size'] + '_' + df['Outlet_Type']\n",
    "    \n",
    "    # Item identifier features\n",
    "    df['Item_Code'] = df['Item_Identifier'].str[0:2]\n",
    "    df['Item_Code'] = df['Item_Code'].astype('category')\n",
    "    \n",
    "    # Log transformations for skewed features\n",
    "    df['Item_Visibility_Log'] = np.log1p(df['Item_Visibility'])\n",
    "    \n",
    "    # Item count per outlet\n",
    "    df['Item_Count_Per_Outlet'] = df.groupby('Outlet_Identifier')['Item_Identifier'].transform('count')\n",
    "    \n",
    "    # Average MRP per outlet\n",
    "    df['Avg_MRP_Per_Outlet'] = df.groupby('Outlet_Identifier')['Item_MRP'].transform('mean')\n",
    "    \n",
    "    # Items per outlet type\n",
    "    df['Items_Per_Outlet_Type'] = df.groupby('Outlet_Type')['Item_Identifier'].transform('count')\n",
    "    \n",
    "     # Price ratio compared to outlet average\n",
    "    df['Price_Ratio_To_Outlet_Avg'] = df['Item_MRP'] / df['Avg_MRP_Per_Outlet']\n",
    "    \n",
    "    # Categorical encoding\n",
    "    for col in ['Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'Item_Fat_Content', \n",
    "                'Price_Level', 'Item_Category', 'Item_Code', 'Outlet_Size_Type']:\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "    \n",
    "     # Drop unnecessary columns\n",
    "    df.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a74a8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    \"\"\"Preprocess data with feature engineering and prepare for modeling\"\"\"\n",
    "    # Combine datasets for consistent preprocessing\n",
    "    train_data['source'] = 'train'\n",
    "    test_data['source'] = 'test'\n",
    "    \n",
    "    \n",
    "    # Save target variable from train data\n",
    "    if 'Item_Outlet_Sales' in train_data.columns:\n",
    "        train_target = train_data['Item_Outlet_Sales']\n",
    "        train_data.drop(['Item_Outlet_Sales'], axis=1, inplace=True)\n",
    "    else:\n",
    "        train_target = None\n",
    "        \n",
    "    \n",
    "    # Combine datasets\n",
    "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    combined_data = advanced_feature_engineering(combined_data)\n",
    "    \n",
    "     # Split back to train and test\n",
    "    train_processed = combined_data[combined_data['source'] == 'train'].drop(['source'], axis=1)\n",
    "    test_processed = combined_data[combined_data['source'] == 'test'].drop(['source'], axis=1)\n",
    "    \n",
    "    return train_processed, test_processed, train_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "679b44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_model(X_train, y_train, X_test, cv=5):\n",
    "    \n",
    "    \"\"\"Build a stacked model with multiple base models and a meta-learner\"\"\"\n",
    "    # Define categorical and numerical columns\n",
    "    categorical_cols = X_train.select_dtypes(include=['category']).columns\n",
    "    numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "     # Create preprocessing pipelines\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    \n",
    "     # Define base models with optimized hyperparameters\n",
    "    base_models = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=300, max_depth=15, min_samples_split=5, \n",
    "                                     min_samples_leaf=2, n_jobs=-1, random_state=42)),\n",
    "        ('gbr', GradientBoostingRegressor(n_estimators=500, learning_rate=0.05, max_depth=5, \n",
    "                                          subsample=0.8, random_state=42)),\n",
    "        ('xgb', xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=6, \n",
    "                             colsample_bytree=0.8, subsample=0.8, reg_alpha=0.1, \n",
    "                             reg_lambda=1, random_state=42)),\n",
    "        ('lgbm', lgbm.LGBMRegressor(n_estimators=500, learning_rate=0.05, num_leaves=31, \n",
    "                               feature_fraction=0.8, bagging_fraction=0.8, lambda_l1=0.1, \n",
    "                               lambda_l2=1, random_state=42)),\n",
    "        ('cbr', cbr.CatBoostRegressor(iterations=500, learning_rate=0.05, depth=6, l2_leaf_reg=3, \n",
    "                                 random_state=42, verbose=0)),\n",
    "        ('et', ExtraTreesRegressor(n_estimators=300, max_depth=15, min_samples_split=5, \n",
    "                                   min_samples_leaf=2, n_jobs=-1, random_state=42)),\n",
    "        ('ridge', Ridge(alpha=0.5, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Train base models using K-fold cross-validation\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize arrays to store meta-features\n",
    "    X_train_meta = np.zeros((X_train.shape[0], len(base_models)))\n",
    "    X_test_meta = np.zeros((X_test.shape[0], len(base_models)))\n",
    "    \n",
    "    # Train base models and generate meta-features\n",
    "    for i, (name, model) in enumerate(base_models):\n",
    "        print(f\"Training {name}...\")\n",
    "        X_test_pred_fold = np.zeros((X_test.shape[0], cv))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # Preprocess data\n",
    "            X_fold_train_processed = preprocessor.fit_transform(X_fold_train)\n",
    "            X_fold_val_processed = preprocessor.transform(X_fold_val)\n",
    "            X_test_processed = preprocessor.transform(X_test)\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_fold_train_processed, y_fold_train)\n",
    "            \n",
    "            # Generate predictions for validation and test sets\n",
    "            X_train_meta[val_idx, i] = model.predict(X_fold_val_processed)\n",
    "            X_test_pred_fold[:, fold] = model.predict(X_test_processed)\n",
    "        \n",
    "        # Average predictions across folds for test set\n",
    "        X_test_meta[:, i] = X_test_pred_fold.mean(axis=1)\n",
    "        \n",
    "    # Train meta-model on meta-features\n",
    "    meta_models = [\n",
    "        Ridge(alpha=0.5),\n",
    "        Lasso(alpha=0.1),\n",
    "        ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "    ]\n",
    "\n",
    "    meta_predictions = []\n",
    "    for meta_model in meta_models:\n",
    "        meta_model.fit(X_train_meta, y_train)\n",
    "        meta_predictions.append(meta_model.predict(X_test_meta))\n",
    "    \n",
    "    # Final ensemble prediction (average of meta-model predictions)\n",
    "    final_predictions = np.mean(meta_predictions, axis=0)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b926057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate Root Mean Squared Error\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c02121ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(X, y, model_func, cv=5):\n",
    "    \"\"\"Validate model performance using cross-validation\"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Get predictions for validation set\n",
    "        y_pred = model_func(X_train, y_train, X_val)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        fold_rmse = rmse(y_val, y_pred)\n",
    "        rmse_scores.append(fold_rmse)\n",
    "    \n",
    "    print(f\"Cross-validation RMSE: {np.mean(rmse_scores):.4f} ± {np.std(rmse_scores):.4f}\")\n",
    "    return np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "229b9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_analysis(X, y):\n",
    "    \"\"\"Analyze feature importance using multiple models\"\"\"\n",
    "    # Define categorical and numerical columns\n",
    "    categorical_cols = X.select_dtypes(include=['category']).columns\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    # Transform the data\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    # Get feature names after one-hot encoding\n",
    "    cat_features = preprocessor.transformers_[1][1].get_feature_names_out(categorical_cols)\n",
    "    feature_names = np.append(numerical_cols, cat_features)\n",
    "    \n",
    "    # Train models and get feature importance\n",
    "    models = [\n",
    "        ('Random Forest', RandomForestRegressor(n_estimators=200, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(n_estimators=200, random_state=42)),\n",
    "        ('LightGBM', LGBMRegressor(n_estimators=200, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    feature_importances = {}\n",
    "    \n",
    "    for name, model in models:\n",
    "        model.fit(X_processed, y)\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        else:\n",
    "            importances = model.coef_\n",
    "            \n",
    "        # Store feature importances\n",
    "        feature_importances[name] = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "    \n",
    "    # Average importance across models\n",
    "    avg_importance = pd.DataFrame(feature_importances).mean(axis=1).sort_values(ascending=False)\n",
    "    \n",
    "    return avg_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6688a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b776d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_hyperparameters(X, y, model_type='xgb'):\n",
    "    # Split data for optimization\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define categorical and numerical columns\n",
    "    categorical_cols = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    # Choose model and parameter space based on model_type\n",
    "    if model_type == 'xgb':\n",
    "        model = XGBRegressor(random_state=42, eval_metric='rmse')\n",
    "        param_distributions = {\n",
    "            'n_estimators': randint(100, 1000),\n",
    "            'max_depth': randint(3, 10),\n",
    "            'learning_rate': uniform(0.01, 0.3),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'gamma': uniform(0, 5),\n",
    "            'reg_alpha': uniform(0, 5),\n",
    "            'reg_lambda': uniform(0, 5),\n",
    "            'min_child_weight': randint(1, 10)\n",
    "        }\n",
    "    elif model_type == 'lgbm':\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        param_distributions = {\n",
    "            'n_estimators': randint(100, 1000),\n",
    "            'learning_rate': uniform(0.01, 0.3),\n",
    "            'num_leaves': randint(20, 100),\n",
    "            'max_depth': randint(3, 10),\n",
    "            'min_child_samples': randint(5, 30),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4),\n",
    "            'reg_alpha': uniform(0, 5),\n",
    "            'reg_lambda': uniform(0, 5)\n",
    "        }\n",
    "    elif model_type == 'catboost':\n",
    "        model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "        param_distributions = {\n",
    "            'iterations': randint(100, 1000),\n",
    "            'learning_rate': uniform(0.01, 0.3),\n",
    "            'depth': randint(4, 10),\n",
    "            'l2_leaf_reg': uniform(0, 10),\n",
    "            'border_count': randint(32, 128),\n",
    "            'bagging_temperature': uniform(0, 100),\n",
    "            'random_strength': uniform(0, 1)\n",
    "        }\n",
    "    \n",
    "    # Create pipeline with preprocessing and model\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform randomized search\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions={'model__' + key: value for key, value in param_distributions.items()},\n",
    "        n_iter=30,\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the search\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate best model\n",
    "    best_model = search.best_estimator_\n",
    "    val_pred = best_model.predict(X_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    \n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "    print(f\"Validation RMSE: {val_rmse}\")\n",
    "    \n",
    "    return best_model, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8010c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('train_v9rqX0R.csv')\n",
    "test_data = pd.read_csv('test_AbJTz2l.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f75b396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "train_processed, test_processed, train_target = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2d59b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Price_per_Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>Item_MRP_Binned</th>\n",
       "      <th>Price_Level</th>\n",
       "      <th>Item_Category</th>\n",
       "      <th>Outlet_Size_Type</th>\n",
       "      <th>Item_Code</th>\n",
       "      <th>Item_Visibility_Log</th>\n",
       "      <th>Item_Count_Per_Outlet</th>\n",
       "      <th>Avg_MRP_Per_Outlet</th>\n",
       "      <th>Items_Per_Outlet_Type</th>\n",
       "      <th>Price_Ratio_To_Outlet_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.300</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>26.861204</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>1550</td>\n",
       "      <td>141.163199</td>\n",
       "      <td>9294</td>\n",
       "      <td>1.769648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.920</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>8.153581</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type2</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>1546</td>\n",
       "      <td>141.000899</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.342333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.500</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>8.092457</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>1550</td>\n",
       "      <td>141.163199</td>\n",
       "      <td>9294</td>\n",
       "      <td>1.003222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.200</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>9.484115</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Food</td>\n",
       "      <td>Small_Grocery Store</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>925</td>\n",
       "      <td>141.159742</td>\n",
       "      <td>1805</td>\n",
       "      <td>1.289992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.930</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>6.031512</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Non-Food</td>\n",
       "      <td>High_Supermarket Type1</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>1553</td>\n",
       "      <td>141.128428</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.381648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>6.865</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>214.5218</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>31.248623</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Food</td>\n",
       "      <td>High_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.055230</td>\n",
       "      <td>1553</td>\n",
       "      <td>141.128428</td>\n",
       "      <td>9294</td>\n",
       "      <td>1.520047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>8.380</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.046982</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>108.1570</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>12.906563</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.045912</td>\n",
       "      <td>1548</td>\n",
       "      <td>140.857341</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.767848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>10.600</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>OUT035</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>8.030415</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Non-Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.034581</td>\n",
       "      <td>1550</td>\n",
       "      <td>141.107228</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.603246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>7.210</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.145221</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>103.1332</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>14.304189</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type2</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.135597</td>\n",
       "      <td>1546</td>\n",
       "      <td>141.000899</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.731436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>14.800</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>75.4670</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>5.099122</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>1550</td>\n",
       "      <td>140.821982</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.535904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Weight Item_Fat_Content  Item_Visibility              Item_Type  \\\n",
       "0           9.300          Low Fat         0.016047                  Dairy   \n",
       "1           5.920          Regular         0.019278            Soft Drinks   \n",
       "2          17.500          Low Fat         0.016760                   Meat   \n",
       "3          19.200          Regular         0.065953  Fruits and Vegetables   \n",
       "4           8.930          Low Fat         0.065953              Household   \n",
       "...           ...              ...              ...                    ...   \n",
       "8518        6.865          Low Fat         0.056783            Snack Foods   \n",
       "8519        8.380          Regular         0.046982           Baking Goods   \n",
       "8520       10.600          Low Fat         0.035186     Health and Hygiene   \n",
       "8521        7.210          Regular         0.145221            Snack Foods   \n",
       "8522       14.800          Low Fat         0.044878            Soft Drinks   \n",
       "\n",
       "      Item_MRP Outlet_Identifier Outlet_Size Outlet_Location_Type  \\\n",
       "0     249.8092            OUT049      Medium               Tier 1   \n",
       "1      48.2692            OUT018      Medium               Tier 3   \n",
       "2     141.6180            OUT049      Medium               Tier 1   \n",
       "3     182.0950            OUT010       Small               Tier 3   \n",
       "4      53.8614            OUT013        High               Tier 3   \n",
       "...        ...               ...         ...                  ...   \n",
       "8518  214.5218            OUT013        High               Tier 3   \n",
       "8519  108.1570            OUT045       Small               Tier 2   \n",
       "8520   85.1224            OUT035       Small               Tier 2   \n",
       "8521  103.1332            OUT018      Medium               Tier 3   \n",
       "8522   75.4670            OUT046       Small               Tier 1   \n",
       "\n",
       "            Outlet_Type  Price_per_Weight  ...  Item_MRP_Binned  Price_Level  \\\n",
       "0     Supermarket Type1         26.861204  ...                9       Luxury   \n",
       "1     Supermarket Type2          8.153581  ...                0       Budget   \n",
       "2     Supermarket Type1          8.092457  ...                4      Economy   \n",
       "3         Grocery Store          9.484115  ...                7      Premium   \n",
       "4     Supermarket Type1          6.031512  ...                1       Budget   \n",
       "...                 ...               ...  ...              ...          ...   \n",
       "8518  Supermarket Type1         31.248623  ...                8       Luxury   \n",
       "8519  Supermarket Type1         12.906563  ...                3      Economy   \n",
       "8520  Supermarket Type1          8.030415  ...                1       Budget   \n",
       "8521  Supermarket Type2         14.304189  ...                3      Economy   \n",
       "8522  Supermarket Type1          5.099122  ...                1       Budget   \n",
       "\n",
       "      Item_Category          Outlet_Size_Type Item_Code Item_Visibility_Log  \\\n",
       "0              Food  Medium_Supermarket Type1        FD            0.015920   \n",
       "1              Food  Medium_Supermarket Type2        DR            0.019095   \n",
       "2              Food  Medium_Supermarket Type1        FD            0.016621   \n",
       "3              Food       Small_Grocery Store        FD            0.063869   \n",
       "4          Non-Food    High_Supermarket Type1        NC            0.063869   \n",
       "...             ...                       ...       ...                 ...   \n",
       "8518           Food    High_Supermarket Type1        FD            0.055230   \n",
       "8519           Food   Small_Supermarket Type1        FD            0.045912   \n",
       "8520       Non-Food   Small_Supermarket Type1        NC            0.034581   \n",
       "8521           Food  Medium_Supermarket Type2        FD            0.135597   \n",
       "8522           Food   Small_Supermarket Type1        DR            0.043900   \n",
       "\n",
       "     Item_Count_Per_Outlet Avg_MRP_Per_Outlet  Items_Per_Outlet_Type  \\\n",
       "0                     1550         141.163199                   9294   \n",
       "1                     1546         141.000899                   1546   \n",
       "2                     1550         141.163199                   9294   \n",
       "3                      925         141.159742                   1805   \n",
       "4                     1553         141.128428                   9294   \n",
       "...                    ...                ...                    ...   \n",
       "8518                  1553         141.128428                   9294   \n",
       "8519                  1548         140.857341                   9294   \n",
       "8520                  1550         141.107228                   9294   \n",
       "8521                  1546         141.000899                   1546   \n",
       "8522                  1550         140.821982                   9294   \n",
       "\n",
       "      Price_Ratio_To_Outlet_Avg  \n",
       "0                      1.769648  \n",
       "1                      0.342333  \n",
       "2                      1.003222  \n",
       "3                      1.289992  \n",
       "4                      0.381648  \n",
       "...                         ...  \n",
       "8518                   1.520047  \n",
       "8519                   0.767848  \n",
       "8520                   0.603246  \n",
       "8521                   0.731436  \n",
       "8522                   0.535904  \n",
       "\n",
       "[8523 rows x 23 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed943f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Price_per_Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>Item_MRP_Binned</th>\n",
       "      <th>Price_Level</th>\n",
       "      <th>Item_Category</th>\n",
       "      <th>Outlet_Size_Type</th>\n",
       "      <th>Item_Code</th>\n",
       "      <th>Item_Visibility_Log</th>\n",
       "      <th>Item_Count_Per_Outlet</th>\n",
       "      <th>Avg_MRP_Per_Outlet</th>\n",
       "      <th>Items_Per_Outlet_Type</th>\n",
       "      <th>Price_Ratio_To_Outlet_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.750000</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>5.198178</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>1550</td>\n",
       "      <td>141.163199</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10.520458</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.037708</td>\n",
       "      <td>1543</td>\n",
       "      <td>140.998931</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.619294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.600000</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>Others</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>16.558479</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Non-Food</td>\n",
       "      <td>Small_Grocery Store</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.094924</td>\n",
       "      <td>925</td>\n",
       "      <td>141.159742</td>\n",
       "      <td>1805</td>\n",
       "      <td>1.712626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315000</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>21.193985</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>1543</td>\n",
       "      <td>140.998931</td>\n",
       "      <td>9294</td>\n",
       "      <td>1.099540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.238358</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "      <td>17.693282</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type3</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.112077</td>\n",
       "      <td>1559</td>\n",
       "      <td>141.012347</td>\n",
       "      <td>1559</td>\n",
       "      <td>1.661060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>141.3154</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>13.458610</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>1550</td>\n",
       "      <td>140.821982</td>\n",
       "      <td>9294</td>\n",
       "      <td>1.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.142991</td>\n",
       "      <td>Starchy Foods</td>\n",
       "      <td>169.1448</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>22.255895</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Food</td>\n",
       "      <td>Medium_Supermarket Type2</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.133648</td>\n",
       "      <td>1546</td>\n",
       "      <td>141.000899</td>\n",
       "      <td>1546</td>\n",
       "      <td>1.199601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>118.7440</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>11.874400</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Non-Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.070951</td>\n",
       "      <td>1548</td>\n",
       "      <td>140.857341</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.843009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>15.300000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>Canned</td>\n",
       "      <td>214.6218</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>14.027569</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Non-Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>1543</td>\n",
       "      <td>140.998931</td>\n",
       "      <td>9294</td>\n",
       "      <td>1.522152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>Canned</td>\n",
       "      <td>79.7960</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>8.399579</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Budget</td>\n",
       "      <td>Non-Food</td>\n",
       "      <td>Small_Supermarket Type1</td>\n",
       "      <td>FD</td>\n",
       "      <td>0.099592</td>\n",
       "      <td>1548</td>\n",
       "      <td>140.857341</td>\n",
       "      <td>9294</td>\n",
       "      <td>0.566502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Weight Item_Fat_Content  Item_Visibility           Item_Type  \\\n",
       "0       20.750000          Low Fat         0.007565         Snack Foods   \n",
       "1        8.300000          Regular         0.038428               Dairy   \n",
       "2       14.600000          Low Fat         0.099575              Others   \n",
       "3        7.315000          Low Fat         0.015388         Snack Foods   \n",
       "4       13.238358          Regular         0.118599               Dairy   \n",
       "...           ...              ...              ...                 ...   \n",
       "5676    10.500000          Regular         0.013496         Snack Foods   \n",
       "5677     7.600000          Regular         0.142991       Starchy Foods   \n",
       "5678    10.000000          Low Fat         0.073529  Health and Hygiene   \n",
       "5679    15.300000          Regular         0.065953              Canned   \n",
       "5680     9.500000          Regular         0.104720              Canned   \n",
       "\n",
       "      Item_MRP Outlet_Identifier Outlet_Size Outlet_Location_Type  \\\n",
       "0     107.8622            OUT049      Medium               Tier 1   \n",
       "1      87.3198            OUT017       Small               Tier 2   \n",
       "2     241.7538            OUT010       Small               Tier 3   \n",
       "3     155.0340            OUT017       Small               Tier 2   \n",
       "4     234.2300            OUT027      Medium               Tier 3   \n",
       "...        ...               ...         ...                  ...   \n",
       "5676  141.3154            OUT046       Small               Tier 1   \n",
       "5677  169.1448            OUT018      Medium               Tier 3   \n",
       "5678  118.7440            OUT045       Small               Tier 2   \n",
       "5679  214.6218            OUT017       Small               Tier 2   \n",
       "5680   79.7960            OUT045       Small               Tier 2   \n",
       "\n",
       "            Outlet_Type  Price_per_Weight  ...  Item_MRP_Binned  Price_Level  \\\n",
       "0     Supermarket Type1          5.198178  ...                3      Economy   \n",
       "1     Supermarket Type1         10.520458  ...                2       Budget   \n",
       "2         Grocery Store         16.558479  ...                9       Luxury   \n",
       "3     Supermarket Type1         21.193985  ...                5      Premium   \n",
       "4     Supermarket Type3         17.693282  ...                9       Luxury   \n",
       "...                 ...               ...  ...              ...          ...   \n",
       "5676  Supermarket Type1         13.458610  ...                4      Economy   \n",
       "5677  Supermarket Type2         22.255895  ...                6      Premium   \n",
       "5678  Supermarket Type1         11.874400  ...                4      Economy   \n",
       "5679  Supermarket Type1         14.027569  ...                8       Luxury   \n",
       "5680  Supermarket Type1          8.399579  ...                1       Budget   \n",
       "\n",
       "      Item_Category          Outlet_Size_Type Item_Code Item_Visibility_Log  \\\n",
       "0              Food  Medium_Supermarket Type1        FD            0.007536   \n",
       "1              Food   Small_Supermarket Type1        FD            0.037708   \n",
       "2          Non-Food       Small_Grocery Store        NC            0.094924   \n",
       "3              Food   Small_Supermarket Type1        FD            0.015271   \n",
       "4              Food  Medium_Supermarket Type3        FD            0.112077   \n",
       "...             ...                       ...       ...                 ...   \n",
       "5676           Food   Small_Supermarket Type1        FD            0.013406   \n",
       "5677           Food  Medium_Supermarket Type2        FD            0.133648   \n",
       "5678       Non-Food   Small_Supermarket Type1        NC            0.070951   \n",
       "5679       Non-Food   Small_Supermarket Type1        FD            0.063869   \n",
       "5680       Non-Food   Small_Supermarket Type1        FD            0.099592   \n",
       "\n",
       "     Item_Count_Per_Outlet Avg_MRP_Per_Outlet  Items_Per_Outlet_Type  \\\n",
       "0                     1550         141.163199                   9294   \n",
       "1                     1543         140.998931                   9294   \n",
       "2                      925         141.159742                   1805   \n",
       "3                     1543         140.998931                   9294   \n",
       "4                     1559         141.012347                   1559   \n",
       "...                    ...                ...                    ...   \n",
       "5676                  1550         140.821982                   9294   \n",
       "5677                  1546         141.000899                   1546   \n",
       "5678                  1548         140.857341                   9294   \n",
       "5679                  1543         140.998931                   9294   \n",
       "5680                  1548         140.857341                   9294   \n",
       "\n",
       "      Price_Ratio_To_Outlet_Avg  \n",
       "0                      0.764096  \n",
       "1                      0.619294  \n",
       "2                      1.712626  \n",
       "3                      1.099540  \n",
       "4                      1.661060  \n",
       "...                         ...  \n",
       "5676                   1.003504  \n",
       "5677                   1.199601  \n",
       "5678                   0.843009  \n",
       "5679                   1.522152  \n",
       "5680                   0.566502  \n",
       "\n",
       "[5681 rows x 23 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ba76bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rf...\n",
      "Training gbr...\n",
      "Training xgb...\n",
      "Training lgbm...\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2210.182308\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2223.009761\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2192.200458\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2194.158120\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2192.278867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training cbr...\n",
      "Training et...\n",
      "Training ridge...\n",
      "Training rf...\n",
      "Training gbr...\n",
      "Training xgb...\n",
      "Training lgbm...\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2182.427946\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2186.027831\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2106\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2198.500167\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2206.394316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2174.606913\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training cbr...\n",
      "Training et...\n",
      "Training ridge...\n",
      "Training rf...\n",
      "Training gbr...\n",
      "Training xgb...\n",
      "Training lgbm...\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2189.139780\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2106\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2186.983560\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2103\n",
      "[LightGBM] [Info] Number of data points in the train set: 5454, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2178.702200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2198.505043\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2177.397780\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training cbr...\n",
      "Training et...\n",
      "Training ridge...\n",
      "Training rf...\n",
      "Training gbr...\n",
      "Training xgb...\n",
      "Training lgbm...\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2106\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2149.206184\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2109\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2186.627929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2106\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2166.150703\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2171.895746\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 5456, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2167.221712\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training cbr...\n",
      "Training et...\n",
      "Training ridge...\n",
      "Training rf...\n",
      "Training gbr...\n",
      "Training xgb...\n",
      "Training lgbm...\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2175.763854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2143.501786\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2161.316055\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2109\n",
      "[LightGBM] [Info] Number of data points in the train set: 5455, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2154.764974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 5456, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2165.285571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training cbr...\n",
      "Training et...\n",
      "Training ridge...\n",
      "Cross-validation RMSE: 1083.4888 ± 37.0893\n",
      "Expected submission score: 1083.4888\n"
     ]
    }
   ],
   "source": [
    "# Validate model performance using cross-validation\n",
    "cv_rmse = validate_model(train_processed, train_target, build_stacked_model)\n",
    "print(f\"Expected submission score: {cv_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a7824a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rf...\n",
      "Training gbr...\n",
      "Training xgb...\n",
      "Training lgbm...\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 6818, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2202.365232\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 6818, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2189.591501\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 6818, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2186.145805\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 6819, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2168.220418\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2104\n",
      "[LightGBM] [Info] Number of data points in the train set: 6819, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 2160.126637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training cbr...\n",
      "Training et...\n",
      "Training ridge...\n"
     ]
    }
   ],
   "source": [
    "# Train final model and make predictions\n",
    "final_predictions = build_stacked_model(train_processed, train_target, test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7e1f3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Item_Identifier': test_data['Item_Identifier'],\n",
    "    'Outlet_Identifier': test_data['Outlet_Identifier'],\n",
    "    'Item_Outlet_Sales': final_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cf867a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4763865287872481"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"Item_Outlet_Sales\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cf8b88cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative predictions: 0\n"
     ]
    }
   ],
   "source": [
    "# Identify negative predictions\n",
    "negative_mask = submission['Item_Outlet_Sales'] < 0\n",
    "negative_indices = submission[negative_mask].index\n",
    "print(f\"Number of negative predictions: {len(negative_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bfbbbd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply absolute value transformation to negative predictions only\n",
    "submission.loc[negative_mask, 'Item_Outlet_Sales'] = submission.loc[negative_mask, 'Item_Outlet_Sales'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ae795a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Item_Identifier, Outlet_Identifier, Item_Outlet_Sales]\n",
       "Index: []"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['Item_Outlet_Sales'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6fe51f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv('submission_10.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572ca81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
